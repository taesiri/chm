{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from model.base.geometry import Geometry\n",
    "from common.evaluation import Evaluator\n",
    "from common.logger import AverageMeter\n",
    "from common.logger import Logger\n",
    "from data import download\n",
    "from model import chmnet\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ConnectionPatch\n",
    "from ipywidgets import interact, interactive, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CUDA Status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure I am using only One GPU!\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model and Parameter Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict({\n",
    "    'alpha' : [0.05, 0.1], \n",
    "    'benchmark':'pfpascal', \n",
    "    'bsz':32, \n",
    "    'datapath':'../Datasets_CHM', \n",
    "    'img_size':240, \n",
    "    'ktype':'psi', \n",
    "    'load':'pretrained/pas_psi.pt',\n",
    "    'thres':'img'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = chmnet.CHMNet(args['ktype']).cuda()\n",
    "model.load_state_dict(torch.load(args['load']))\n",
    "Evaluator.initialize(args['alpha'])\n",
    "Geometry.initialize(img_size=args['img_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = transforms.Compose(\n",
    "   [transforms.Resize((args['img_size'], args['img_size'])),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class point_selection_widget():\n",
    "#   %matplotlib notebook \n",
    "  def __init__(self, im):\n",
    "    self.im = im\n",
    "    self.selected_points = []\n",
    "    self.fig, self.ax = plt.subplots()\n",
    "    self.img = self.ax.imshow(self.im.copy())\n",
    "    self.ka = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
    "    disconnect_button = widgets.Button(description=\"End Point Selection\")\n",
    "    Disp.display(disconnect_button)\n",
    "    disconnect_button.on_click(self.disconnect_mpl)\n",
    "\n",
    "  def update_dots(self, img, pts):\n",
    "    pts = np.array(pts, np.int32)\n",
    "    pts = pts.T\n",
    "    self.ax.imshow(img)\n",
    "    self.ax.scatter(pts[0, :], pts[1, :], c='red')\n",
    "\n",
    "  def onclick(self, event):\n",
    "    self.selected_points.append([event.xdata, event.ydata])\n",
    "    if len(self.selected_points)>1:\n",
    "      self.fig\n",
    "      self.update_dots(self.im.copy(), self.selected_points)\n",
    "\n",
    "  def disconnect_mpl(self,_):\n",
    "      self.fig.canvas.mpl_disconnect(self.ka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "\n",
    "for k in range(40):\n",
    "  colors.append(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CHM and Visualize the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(imageA_path, imgaeB_path, selected_points, plot_title='CHM Keypoint Transfer Output'):\n",
    "  # Load Images\n",
    "  src_pil_img = Image.open(imageA_path).convert('RGB')\n",
    "  tgt_pil_img = Image.open(imgaeB_path).convert('RGB')\n",
    "  # Convert to Tensor\n",
    "  src_img_tnsr = my_transform(src_pil_img).unsqueeze(0)\n",
    "  tgt_img_tnsr = my_transform(tgt_pil_img).unsqueeze(0)\n",
    "  \n",
    "  # SRC POINT PREPARATION\n",
    "  src_w, src_h = src_pil_img.size\n",
    "  selected_points[:, 0] = 240*selected_points[:, 0] / src_w\n",
    "  selected_points[:, 1] = 240*selected_points[:, 1] / src_h\n",
    "\n",
    "  selected_points = selected_points.T \n",
    "  keypoints = torch.tensor(selected_points).unsqueeze(0)\n",
    "  n_pts = torch.tensor(np.asarray([selected_points.shape[1]])) # Must be an Integer Tensor\n",
    "\n",
    "  # RUN CHM\n",
    "  with torch.no_grad():\n",
    "    corr_matrix = model(src_img_tnsr.cuda(), tgt_img_tnsr.cuda())\n",
    "    prd_kps = Geometry.transfer_kps(corr_matrix, keypoints.cuda(), n_pts.cuda(), normalized=False)\n",
    "    \n",
    "  # VISUALIZATION\n",
    "  src_points = keypoints[0].squeeze(0).squeeze(0).numpy()\n",
    "  tgt_points = prd_kps[0].squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "  nkpts = selected_points.shape[1]\n",
    "\n",
    "  src_points_converted  = []\n",
    "  w, h = src_pil_img.size\n",
    "\n",
    "  for x,y in zip(src_points[0], src_points[1]):\n",
    "    src_points_converted.append([int(x*w/args['img_size']),int((y)*h/args['img_size'])])\n",
    "\n",
    "  src_points_converted = np.asarray(src_points_converted[:nkpts])\n",
    "  tgt_points_converted  = []\n",
    "\n",
    "  w, h = tgt_pil_img.size\n",
    "\n",
    "  for x,y in zip(tgt_points[0], tgt_points[1]):\n",
    "    tgt_points_converted.append([int(((x+1)/2.0)*w),int(((y+1)/2.0)*h)])\n",
    "\n",
    "  tgt_points_converted = np.asarray(tgt_points_converted[:nkpts])\n",
    "\n",
    "  # PLOT\n",
    "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "\n",
    "  ax[0].imshow(src_pil_img)\n",
    "  ax[0].scatter(src_points_converted[:, 0], src_points_converted[:, 1], c=colors[:nkpts])\n",
    "  ax[0].set_title('Source')\n",
    "  ax[0].set_xticks([])\n",
    "  ax[0].set_yticks([])\n",
    "\n",
    "  ax[1].imshow(tgt_pil_img)\n",
    "  ax[1].scatter(tgt_points_converted[:, 0], tgt_points_converted[:, 1], c=colors[:nkpts])\n",
    "  ax[1].set_title('Target')\n",
    "  ax[1].set_xticks([])\n",
    "  ax[1].set_yticks([])\n",
    "  for i in range(nkpts):\n",
    "    con = ConnectionPatch(xyA=src_points_converted[i], \n",
    "                        xyB=tgt_points_converted[i], \n",
    "                        coordsA=\"data\", \n",
    "                        coordsB=\"data\",\n",
    "                        axesA=ax[0], axesB=ax[1], color=colors[i])\n",
    "    ax[1].add_artist(con)\n",
    "\n",
    "    ax[0].plot(src_points_converted[i][0], src_points_converted[i][1], markersize=6, color=colors[i])\n",
    "    ax[1].plot(tgt_points_converted[i][0], tgt_points_converted[i][1], markersize=6, color=colors[i])\n",
    "\n",
    "  fig.suptitle(plot_title, fontsize=16)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob('sample_images/n01532829/*.jpeg')\n",
    "images = [Image.open(img) for img in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class browse_images():\n",
    "  def __init__(self, image_list):\n",
    "    self.image_list = image_list\n",
    "    self.n = len(image_list)\n",
    "    self.fig, self.axes = plt.subplots(1, 2)\n",
    "    self.values = [0, 0]\n",
    "    \n",
    "    interact(self.view_image, index=fixed(0), i=(0, self.n-1))\n",
    "    interact(self.view_image, index=fixed(1), i=(0, self.n-1))    \n",
    "    \n",
    "  def view_image(self, index, i, ):\n",
    "    self.values[index] = i\n",
    "    self.axes[index].imshow(self.image_list[i])\n",
    "    self.axes[index].set_title(f'Selected image: {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrowser = browse_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrowser.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Source Points\n",
    "\n",
    "An interactive widget to choose keypoints on the source image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(image_paths[ibrowser.values[0]])\n",
    "pselector = point_selection_widget(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pselector.selected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(image_paths[ibrowser.values[0]], image_paths[ibrowser.values[1]], np.asarray(pselector.selected_points), plot_title='CHM Keypoint Transfer Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "\n",
    "for k in range(40):\n",
    "  colors.append(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "955b9905898a706155cc96e86563569d49e09298d16f32c8c8176b8489ac5c8d"
  },
  "kernelspec": {
   "display_name": "DEEP36",
   "language": "python",
   "name": "deep36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
