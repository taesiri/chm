{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from model.base.geometry import Geometry\n",
    "from common.evaluation import Evaluator\n",
    "from common.logger import AverageMeter\n",
    "from common.logger import Logger\n",
    "from data import download\n",
    "from model import chmnet\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ConnectionPatch\n",
    "from ipywidgets import interact, interactive, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CUDA Status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# Make sure I am using only One GPU!\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model and Parameter Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict({\n",
    "    'alpha' : [0.05, 0.1], \n",
    "    'benchmark':'pfpascal', \n",
    "    'bsz':32, \n",
    "    'datapath':'../Datasets_CHM', \n",
    "    'img_size':240, \n",
    "    'ktype':'psi', \n",
    "    'load':'pretrained/pas_psi.pt',\n",
    "    'thres':'img'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = chmnet.CHMNet(args['ktype']).cuda()\n",
    "model.load_state_dict(torch.load(args['load']))\n",
    "Evaluator.initialize(args['alpha'])\n",
    "Geometry.initialize(img_size=args['img_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = transforms.Compose(\n",
    "   [transforms.Resize((args['img_size'], args['img_size'])),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as Disp\n",
    "from ipywidgets import widgets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class point_selection_widget():\n",
    "#   %matplotlib notebook \n",
    "  def __init__(self, im):\n",
    "    self.im = im\n",
    "    self.selected_points = []\n",
    "    self.fig, self.ax = plt.subplots()\n",
    "    self.img = self.ax.imshow(self.im.copy())\n",
    "    self.ka = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
    "    disconnect_button = widgets.Button(description=\"End Point Selection\")\n",
    "    Disp.display(disconnect_button)\n",
    "    disconnect_button.on_click(self.disconnect_mpl)\n",
    "\n",
    "  def update_dots(self, img, pts):\n",
    "    pts = np.array(pts, np.int32)\n",
    "    pts = pts.T\n",
    "    self.ax.imshow(img)\n",
    "    self.ax.scatter(pts[0, :], pts[1, :], c='red')\n",
    "\n",
    "  def onclick(self, event):\n",
    "    self.selected_points.append([event.xdata, event.ydata])\n",
    "    if len(self.selected_points)>1:\n",
    "      self.fig\n",
    "      self.update_dots(self.im.copy(), self.selected_points)\n",
    "\n",
    "  def disconnect_mpl(self,_):\n",
    "      self.fig.canvas.mpl_disconnect(self.ka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "\n",
    "for k in range(40):\n",
    "  colors.append(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CHM and Visualize the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(imageA_path, imgaeB_path, selected_points, plot_title='CHM Keypoint Transfer Output'):\n",
    "  # Load Images\n",
    "  src_pil_img = Image.open(imageA_path).convert('RGB')\n",
    "  tgt_pil_img = Image.open(imgaeB_path).convert('RGB')\n",
    "  # Convert to Tensor\n",
    "  src_img_tnsr = my_transform(src_pil_img).unsqueeze(0)\n",
    "  tgt_img_tnsr = my_transform(tgt_pil_img).unsqueeze(0)\n",
    "  \n",
    "  # SRC POINT PREPARATION\n",
    "  src_w, src_h = src_pil_img.size\n",
    "  selected_points[:, 0] = 240*selected_points[:, 0] / src_w\n",
    "  selected_points[:, 1] = 240*selected_points[:, 1] / src_h\n",
    "\n",
    "  selected_points = selected_points.T \n",
    "  keypoints = torch.tensor(selected_points).unsqueeze(0)\n",
    "  n_pts = torch.tensor(np.asarray([selected_points.shape[1]])) # Must be an Integer Tensor\n",
    "\n",
    "  # RUN CHM\n",
    "  with torch.no_grad():\n",
    "    corr_matrix = model(src_img_tnsr.cuda(), tgt_img_tnsr.cuda())\n",
    "    prd_kps = Geometry.transfer_kps(corr_matrix, keypoints.cuda(), n_pts.cuda(), normalized=False)\n",
    "    \n",
    "  # VISUALIZATION\n",
    "  src_points = keypoints[0].squeeze(0).squeeze(0).numpy()\n",
    "  tgt_points = prd_kps[0].squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "  nkpts = selected_points.shape[1]\n",
    "\n",
    "  src_points_converted  = []\n",
    "  w, h = src_pil_img.size\n",
    "\n",
    "  for x,y in zip(src_points[0], src_points[1]):\n",
    "    src_points_converted.append([int(x*w/args['img_size']),int((y)*h/args['img_size'])])\n",
    "\n",
    "  src_points_converted = np.asarray(src_points_converted[:nkpts])\n",
    "  tgt_points_converted  = []\n",
    "\n",
    "  w, h = tgt_pil_img.size\n",
    "\n",
    "  for x,y in zip(tgt_points[0], tgt_points[1]):\n",
    "    tgt_points_converted.append([int(((x+1)/2.0)*w),int(((y+1)/2.0)*h)])\n",
    "\n",
    "  tgt_points_converted = np.asarray(tgt_points_converted[:nkpts])\n",
    "\n",
    "  # PLOT\n",
    "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "\n",
    "  ax[0].imshow(src_pil_img)\n",
    "  ax[0].scatter(src_points_converted[:, 0], src_points_converted[:, 1], c=colors[:nkpts])\n",
    "  ax[0].set_title('Source')\n",
    "  ax[0].set_xticks([])\n",
    "  ax[0].set_yticks([])\n",
    "\n",
    "  ax[1].imshow(tgt_pil_img)\n",
    "  ax[1].scatter(tgt_points_converted[:, 0], tgt_points_converted[:, 1], c=colors[:nkpts])\n",
    "  ax[1].set_title('Target')\n",
    "  ax[1].set_xticks([])\n",
    "  ax[1].set_yticks([])\n",
    "  for i in range(nkpts):\n",
    "    con = ConnectionPatch(xyA=src_points_converted[i], \n",
    "                        xyB=tgt_points_converted[i], \n",
    "                        coordsA=\"data\", \n",
    "                        coordsB=\"data\",\n",
    "                        axesA=ax[0], axesB=ax[1], color=colors[i])\n",
    "    ax[1].add_artist(con)\n",
    "\n",
    "    ax[0].plot(src_points_converted[i][0], src_points_converted[i][1], markersize=6, color=colors[i])\n",
    "    ax[1].plot(tgt_points_converted[i][0], tgt_points_converted[i][1], markersize=6, color=colors[i])\n",
    "\n",
    "  fig.suptitle(plot_title, fontsize=16)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob('sample_images/n01532829/*.jpeg')\n",
    "images = [Image.open(img) for img in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class browse_images():\n",
    "  def __init__(self, image_list):\n",
    "    self.image_list = image_list\n",
    "    self.n = len(image_list)\n",
    "    self.fig, self.axes = plt.subplots(1, 2)\n",
    "    self.values = [0, 0]\n",
    "    \n",
    "    interact(self.view_image, index=fixed(0), i=(0, self.n-1))\n",
    "    interact(self.view_image, index=fixed(1), i=(0, self.n-1))    \n",
    "    \n",
    "  def view_image(self, index, i, ):\n",
    "    self.values[index] = i\n",
    "    self.axes[index].imshow(self.image_list[i])\n",
    "    self.axes[index].set_title(f'Selected image: {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70c8a7bab7940f5b3e88a0094928b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb848aa0b5614a34a969f90e260146e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='i', max=9), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6030e36bba564b37b151a7741d844040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='i', max=9), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ibrowser = browse_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibrowser.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Source Points\n",
    "\n",
    "An interactive widget to choose keypoints on the source image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238cb9282c31406092a19f531d8aa6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b51ce0bfa14b85a1bea097df60f708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='End Point Selection', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = plt.imread(image_paths[ibrowser.values[0]])\n",
    "pselector = point_selection_widget(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[266.56063142586584, 108.24068249458867],\n",
       " [299.095804586039, 118.65193790584408],\n",
       " [267.86203835227275, 165.50258725649343],\n",
       " [191.07902969426405, 153.78992491883105],\n",
       " [222.31279592803028, 272.2179552218614],\n",
       " [262.656410646645, 325.5756392045454],\n",
       " [273.0676660579004, 368.52206777597394]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pselector.selected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/miniconda3/envs/deep36/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448233824/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/mohammad/miniconda3/envs/deep36/lib/python3.6/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448233824/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea0954ee3e541c087acacd090c1a957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_model(image_paths[ibrowser.values[0]], image_paths[ibrowser.values[1]], np.asarray(pselector.selected_points), plot_title='CHM Keypoint Transfer Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "\n",
    "for k in range(40):\n",
    "  colors.append(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "955b9905898a706155cc96e86563569d49e09298d16f32c8c8176b8489ac5c8d"
  },
  "kernelspec": {
   "display_name": "DEEP36",
   "language": "python",
   "name": "deep36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
